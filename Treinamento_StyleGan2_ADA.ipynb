{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Treinamento StyleGan2-ADA",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filipecalegario/stylegan2-ada-experiments/blob/main/Treinamento_StyleGan2_ADA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UDVO2FGKIQw"
      },
      "source": [
        "# StyleGAN2-ADA (PyTorch): Treinando um modelo a partir de imagens pré-processadas\n",
        "\n",
        "Referência: https://github.com/NVlabs/stylegan2-ada-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOAy1OXOUjCe"
      },
      "source": [
        "## Configurações Iniciais\n",
        "\n",
        "**Dica**: Caso seu modelo demore algumas horas para ser treinado (provavelmente levará), é normal que o Colab te desconecte durante o treinamento algumas vezes. Usando o Colab Pro, a frequência dessas desconexões será bastante reduzida. Caso ainda prefira utilizar o Colab Free, dê uma olhada nesse artigo para diminuir a frequência das desconexões: \n",
        "<br>\n",
        "https://medium.com/@shivamrawat_756/how-to-prevent-google-colab-from-disconnecting-717b88a128c0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVhbmoa_gbyQ"
      },
      "source": [
        "### Checar uso de GPU (placa de vídeo)\n",
        "\n",
        "Ao executar a célula a seguir, é esperado que você veja uma tabela com as configurações da placa de vídeo atualmente utilizada por seu ambiente de execução.\n",
        "<br>\n",
        "Caso o comando a seguir falhe, vá no menu do canto superior esquerdo e, na aba ***Runtime***, entre em ***Change runtime type***. Dentro desse novo menu, vá em ***Hardware accelerator*** e selecione a opção ***GPU***, por fim salve.\n",
        "<br>\n",
        "Rode novamente a célula abaixo para checar se o ambiente de execução agora tem uma placa de vídeo conectada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZN1hu6CgbYU"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlNLZOGTpll-"
      },
      "source": [
        "### Instalação de pré-requisitos\n",
        "\n",
        "Referência: https://github.com/NVlabs/stylegan2-ada-pytorch/issues/2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-yNo3MWpsV8"
      },
      "source": [
        "%pip install ninja"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0oZRRs2KO5A"
      },
      "source": [
        "### Baixar código do StyleGAN2-ADA (PyTorch)\n",
        "\n",
        "Referência: https://github.com/woctezuma/stylegan2-ada-pytorch/tree/google-colab \n",
        "<br>\n",
        "Fork utilizada: https://github.com/ClaudioCarvalhoo/stylegan2-ada-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKYZ49zf41Sv"
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "%rm -rf stylegan2-ada-pytorch/\n",
        "!git clone https://github.com/ClaudioCarvalhoo/stylegan2-ada-pytorch\n",
        "\n",
        "%cd stylegan2-ada-pytorch/\n",
        "\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MZrLN2ZDAO2"
      },
      "source": [
        "## Conectar com Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56qhqOqGDFu7"
      },
      "source": [
        "%pip install Google-Colab-Transfer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDqwTKCYAqIn"
      },
      "source": [
        "Ao executar a próxima célula, você receberá um link para pegar seu código de verificação do Google Drive.\n",
        "<br>\n",
        "Acesse com sua conta que tem as imagens de treinamento no Drive e cole o código recebido na caixa de texto que aparecerá abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBN0678aDGlk"
      },
      "source": [
        "import colab_transfer\n",
        "\n",
        "colab_transfer.mount_google_drive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3jq9l7sBf3r"
      },
      "source": [
        "Após executar a próxima célula, insira nas caixas de texto o caminho para a pasta do seu Drive que contém as imagens pré-processadas anteriormente geradas e também o caminho para a pasta do seu Drive na qual deseja salvar seu modelo.\n",
        "<br>\n",
        "Lembre-se de manter intacta a parte inicial do texto (/content/drive/MyDrive/) pois é o caminho do Colab para acessar a raíz de seu Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kan7WzrDHZJ"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "dataset = widgets.Text(\n",
        "    value='/content/drive/MyDrive/sua_pasta/dataset',\n",
        "    placeholder='Digite ou cole aqui o caminho',\n",
        "    layout=widgets.Layout(width='50%')\n",
        ")\n",
        "output_folder = widgets.Text(\n",
        "    value='/content/drive/MyDrive/sua_pasta/modelos',\n",
        "    placeholder='Digite ou cole aqui o caminho',\n",
        "    layout=widgets.Layout(width='50%')\n",
        ")\n",
        "widgets.VBox([\n",
        "    widgets.VBox([widgets.Label('Caminho para as imagens processadas:'), dataset]),          \n",
        "    widgets.VBox([widgets.Label('Caminho para salvar o modelo:'), output_folder])\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWpIjP7hKzJZ"
      },
      "source": [
        "## Treinando sua rede\n",
        "\n",
        "Referência: https://github.com/NVlabs/stylegan2-ada-pytorch#training-new-networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUKiyWY22dzf"
      },
      "source": [
        "### Executando o treinamento\n",
        "\n",
        "Uma vez que o treinamento for iniciado, ele criará modelos intermediários e salvará eles no seu Drive como arquivos que têm a extensão *.pkl*. Como normalmente não conseguimos realizar o treinamento completo em uma única execução (pois o Colab desconecta depois de um tempo), utilizaremos o mais recente destes modelos intermediários para retormar nosso treinamento quando nos reconectarmos.<br><br>\n",
        "\n",
        "*   Primeira Execução\n",
        "\n",
        "Coloque o valor **noresume** na caixa de texto abaixo para começar o treinamento do zero.\n",
        "\n",
        "*   Retomando a Execução\n",
        "\n",
        "Coloque o caminho para o último modelo (arquivo *.pkl*) criado em seu Drive, para que possamos retomar a partir dele."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_r4D_NuFj_3"
      },
      "source": [
        "resume = widgets.Text(\n",
        "    value='noresume',\n",
        "    placeholder='Insira aqui o caminho para o modelo',\n",
        "    layout=widgets.Layout(width='50%')\n",
        ")\n",
        "    \n",
        "widgets.VBox([widgets.Label('Caminho para retomar treinamento:'), resume]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SddkXE48K64V"
      },
      "source": [
        "A célula abaixo contém alguns parâmetros para o treinamento de seu modelo, que podem ser ajustados caso deseje estudar sobre os efeitos de cada um.\n",
        "<br>\n",
        "Atenção para o parâmetro \"mini_batch\". Caso ao rodar o treinamento você receba um erro alegando falta de memória, experimente diminuir o mini_batch e rodar novamente a célula abaixo. Normalmente o valor 16 já resolve a maioria dos casos, mas tente usar 32 antes se conseguir sem erros pois terá maior eficiência."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97U6mcsuoCiI"
      },
      "source": [
        "snap = 5\n",
        "gamma = 10\n",
        "kimg = 100000\n",
        "mini_batch = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWdbunTIMkBT"
      },
      "source": [
        "Ao rodar a célula abaixo, você iniciará/retomará seu treinamento. Isso pode potencialmente durar horas, dias ou até mesmo semanas.\n",
        "<br>\n",
        "Lembre-se que não há um momento final no qual seu modelo está \"pronto\". Você deve acompanhar a evolução de seus modelos intermediários à medida que eles forem sendo gerados na pasta que você definiu como destino. Cada modelo será gerado com uma imagem que contém alguns exemplares do que ele é capaz de produzir. Utilize essas imagens para definir quando você considera que tem um modelo que produz bons resultados, nesse momento você poderá parar o treinamento e usar este modelo para o que desejar no futuro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8TWmeqExkda"
      },
      "source": [
        "!python stylegan2-ada-pytorch/train.py \\\n",
        " --outdir={output_folder.value} \\\n",
        " --snap={snap} \\\n",
        " --metrics=none \\\n",
        " --data={dataset.value} \\\n",
        " --cfg=auto_norp \\\n",
        " --cifar_tune=1 \\\n",
        " --gamma={gamma} \\\n",
        " --kimg={kimg} \\\n",
        " --batch={mini_batch} \\\n",
        " --cfg_map=8 \\\n",
        " --augpipe=bg \\\n",
        " --freezed=10 \\\n",
        " --resume={resume.value} \\\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}