{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pré-processamento de Imagens StyleGan2-ADA",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filipecalegario/stylegan2-ada-experiments/blob/main/Pr%C3%A9_processamento_de_Imagens_StyleGan2_ADA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UDVO2FGKIQw"
      },
      "source": [
        "# StyleGAN2-ADA (PyTorch): Pré-processando imagens para treinar um modelo\n",
        "\n",
        "Referência: https://github.com/NVlabs/stylegan2-ada-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOAy1OXOUjCe"
      },
      "source": [
        "## Configurações Iniciais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVhbmoa_gbyQ"
      },
      "source": [
        "### Checar uso de GPU (placa de vídeo)\n",
        "\n",
        "Ao executar a célula a seguir, é esperado que você veja uma tabela com as configurações da placa de vídeo atualmente utilizada por seu ambiente de execução.\n",
        "<br>\n",
        "Caso o comando a seguir falhe, vá no menu do canto superior esquerdo e, na aba ***Runtime***, entre em ***Change runtime type***. Dentro desse novo menu, vá em ***Hardware accelerator*** e selecione a opção ***GPU***, por fim salve.\n",
        "<br>\n",
        "Rode novamente a célula abaixo para checar se o ambiente de execução agora tem uma placa de vídeo conectada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZN1hu6CgbYU"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlNLZOGTpll-"
      },
      "source": [
        "### Instalação de pré-requisitos\n",
        "\n",
        "Referência: https://github.com/NVlabs/stylegan2-ada-pytorch/issues/2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-yNo3MWpsV8"
      },
      "source": [
        "%pip install ninja\n",
        "%pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0oZRRs2KO5A"
      },
      "source": [
        "### Baixar código do StyleGAN2-ADA (PyTorch)\n",
        "\n",
        "Referência: https://github.com/woctezuma/stylegan2-ada-pytorch/tree/google-colab \n",
        "<br>\n",
        "Fork utilizada: https://github.com/ClaudioCarvalhoo/stylegan2-ada-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKYZ49zf41Sv"
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "%rm -rf stylegan2-ada-pytorch/\n",
        "!git clone https://github.com/ClaudioCarvalhoo/stylegan2-ada-pytorch\n",
        "\n",
        "%cd stylegan2-ada-pytorch/\n",
        "\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MZrLN2ZDAO2"
      },
      "source": [
        "## Conectar com Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56qhqOqGDFu7"
      },
      "source": [
        "%pip install Google-Colab-Transfer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BIk4LRiOg1-"
      },
      "source": [
        "Ao executar a próxima célula, você receberá um link para pegar seu código de verificação do Google Drive.\n",
        "<br>\n",
        "Acesse com sua conta que tem as imagens de treinamento no Drive e cole o código recebido na caixa de texto que aparecerá abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBN0678aDGlk"
      },
      "source": [
        "import colab_transfer\n",
        "\n",
        "colab_transfer.mount_google_drive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd78vUQXTduX"
      },
      "source": [
        "## Normalizando Imagens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqPf3E50OolZ"
      },
      "source": [
        "Após executar a próxima célula, insira nas caixas de texto o caminho para a pasta do seu Drive que contém as imagens a serem utilizadas para treinar seu modelo e também o caminho para a pasta do seu Drive na qual deseja salvar as imagens após serem processadas.\n",
        "<br>\n",
        "Lembre-se de manter intacta a parte inicial do texto (/content/drive/MyDrive/) pois é o caminho do Colab para acessar a raíz de seu Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbGZKS0sNC7F"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "custom_images = widgets.Text(\n",
        "    value='/content/drive/MyDrive/sua_pasta/imagens_originais',\n",
        "    placeholder='Digite ou cole aqui o caminho',\n",
        "    layout=widgets.Layout(width='50%')\n",
        ")\n",
        "dataset = widgets.Text(\n",
        "    value='/content/drive/MyDrive/sua_pasta/dataset',\n",
        "    placeholder='Digite ou cole aqui o caminho',\n",
        "    layout=widgets.Layout(width='50%')\n",
        ")\n",
        "widgets.VBox([\n",
        "    widgets.VBox([widgets.Label('Caminho para as imagens originais:'), custom_images]),\n",
        "    widgets.VBox([widgets.Label('Caminho para salvar as imagens processadas:'), dataset])          \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBYK3XgaVyAf"
      },
      "source": [
        "Após executar a próxima célula, escolha um tamanho (em pixels) para a altura e largura das imagens que serão geradas. Quanto maior, mais demorado será o treinamento da rede.\n",
        "<br>\n",
        "Você pode também escolher a maneira com a qual serão geradas bordas para deixar as imagens quadradas. Caso não saiba o que cada um faz, pode deixar no valor padrão!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT6YUWHsUcpH"
      },
      "source": [
        "import cv2\n",
        "\n",
        "IMG_SIZE = widgets.ToggleButtons(\n",
        "    options=[128, 256, 512, 1048],\n",
        "    value=256\n",
        ")\n",
        "BORDER_TYPE = widgets.Dropdown(\n",
        "    options=[('BORDER_REPLICATE', cv2.BORDER_REPLICATE), ('BORDER_CONSTANT', cv2.BORDER_CONSTANT), ('BORDER_REFLECT', cv2.BORDER_REFLECT), ('BORDER_WRAP', cv2.BORDER_WRAP), ('BORDER_REFLECT_101', cv2.BORDER_REFLECT_101), ('BORDER_TRANSPARENT', cv2.BORDER_TRANSPARENT), ('BORDER_REFLECT101', cv2.BORDER_REFLECT101), ('BORDER_DEFAULT', cv2.BORDER_DEFAULT), ('BORDER_ISOLATED', cv2.BORDER_ISOLATED)],\n",
        "    value=cv2.BORDER_REPLICATE,\n",
        ")\n",
        "\n",
        "widgets.VBox([\n",
        "    widgets.Label('Tamanho das imagens geradas:'),\n",
        "    IMG_SIZE,\n",
        "    widgets.Label('Estilo das bordas:'),\n",
        "    BORDER_TYPE\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF0MewdxQLmg"
      },
      "source": [
        "A célula a seguir processará todas as suas imagens deixando-as quadradas e do mesmo tamanho (requisitos obrigatórios para treinamento do StyleGan)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uJbz2B0Tvsn"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def getBorderSizes(size):\n",
        "    necessaryPadding = IMG_SIZE.value - size\n",
        "    borderSize = necessaryPadding // 2\n",
        "    if necessaryPadding % 2 == 0:\n",
        "        return [borderSize, borderSize]\n",
        "    else:\n",
        "        return [borderSize + 1, borderSize]\n",
        "\n",
        "def getDirFiles(dir):\n",
        "  return [f for f in os.listdir(dir) if os.path.isfile(f\"{dir}/{f}\")]\n",
        "\n",
        "processedImagesDir = f\"{custom_images.value}/processed\"\n",
        "processed = set()\n",
        "if \"processed\" in os.listdir(f\"{custom_images.value}\"):\n",
        "  processed = set(\n",
        "      [filename.split(\".\")[0] for filename in getDirFiles(processedImagesDir)]\n",
        "  )\n",
        "else:\n",
        "  os.mkdir(f\"{custom_images.value}/processed\")\n",
        "\n",
        "def processImage(filename):\n",
        "    if len(filename.split(\".\")) <= 1 or filename.split(\".\")[0] in processed:\n",
        "        return\n",
        "\n",
        "    img = cv2.imread(f\"{custom_images.value}/{filename}\")\n",
        "\n",
        "    f1 = IMG_SIZE.value / img.shape[1]\n",
        "    f2 = IMG_SIZE.value / img.shape[0]\n",
        "    f = min(f1, f2)  # resizing factor\n",
        "    dim = (int(img.shape[1] * f), int(img.shape[0] * f))\n",
        "\n",
        "    img = cv2.resize(img, dim)\n",
        "\n",
        "    heightBorders = getBorderSizes(img.shape[0])\n",
        "    widthBorders = getBorderSizes(img.shape[1])\n",
        "\n",
        "    img = cv2.copyMakeBorder(\n",
        "        img,\n",
        "        top=heightBorders[0],\n",
        "        bottom=heightBorders[1],\n",
        "        left=widthBorders[0],\n",
        "        right=widthBorders[1],\n",
        "        borderType=BORDER_TYPE.value,\n",
        "    )\n",
        "\n",
        "    cv2.imwrite(f\"{processedImagesDir}/{filename}.jpg\", img)\n",
        "    print(f\"Processed: {filename}\")\n",
        "\n",
        "for img in getDirFiles(custom_images.value):\n",
        "  processImage(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t80pr43tSET6"
      },
      "source": [
        "## Pré-processando Imagens\n",
        "\n",
        "A célula a seguir transformará suas imagens em um conjunto de dados capaz de ser utilizado para o treinamento da rede.\n",
        "\n",
        "Referência: https://github.com/NVlabs/stylegan2-ada-pytorch#preparing-datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHOLiwbZBT_y"
      },
      "source": [
        "!python stylegan2-ada-pytorch/dataset_tool.py \\\n",
        " --source {processedImagesDir} \\\n",
        " --dest {dataset.value}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}